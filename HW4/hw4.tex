\documentclass[12pt, fullpage,letterpaper]{article}

\usepackage[margin=1in]{geometry}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xspace}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{algorithm2e}

\newcommand{\semester}{Spring 2020}
\newcommand{\assignmentId}{4}
\newcommand{\releaseDate}{19 Mar, 2020}
\newcommand{\dueDate}{11:59pm, 4 Apr, 2020}

\newcommand{\bx}{{\bf x}}
\newcommand{\bw}{{\bf w}}

\title{CS 5350/6350: Machine Learining \semester}
\author{Homework \assignmentId}
\date{Handed out: \releaseDate\\
	Due: \dueDate}


\title{CS 5350/6350: Machine Learning \semester}
\author{Homework \assignmentId}
\date{Handed out: \releaseDate\\
  Due date: \dueDate}

\begin{document}
\maketitle

\input{emacscomm}
\newcommand{\Hcal}{\mathcal{H}} 
{\footnotesize
	\begin{itemize}
		\item You are welcome to talk to other members of the class about
		the homework. I am more concerned that you understand the
		underlying concepts. However, you should write down your own
		solution. Please keep the class collaboration policy in mind.
		
		\item Feel free to discuss the homework with the instructor or the TAs.
		
		\item Your written solutions should be brief and clear. You do not need to include original problem descriptions in your solutions. You need to
		show your work, not just the final answer, but you do \emph{not}
		need to write it in gory detail. Your assignment should be {\bf no
			more than 15 pages}. Every extra page will cost a point.
		
		\item Handwritten solutions will not be accepted.
		
		
		\item {\em Your code should run on the CADE machines}. \textbf{You should
		include a shell script, {\tt run.sh}, that will execute your code
		in the CADE environment. Your code should produce similar output to what you include in your report.}
		
		You are responsible for ensuring that the grader can execute the
		code using only the included script. If you are using an
		esoteric programming language, you should make sure that its
		runtime is available on CADE.
		
		\item Please do not hand in binary files! We will {\em not} grade
		binary submissions.
		
		\item The homework is due by \textbf{midnight of the due date}. Please submit
		the homework on Canvas.
		
	\end{itemize}
}


\section{Paper Problems [40 points + 10 bonus]}
\begin{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%% Q1
	\item~[9 points] The learning of soft SVMs is formulated as the following optimization problem,
		\begin{align}
		\min\limits_{\w, b, \{\xi_i\}} &\;\;\;\frac{1}{2}\w^\top\w + C\sum_i \xi_i 
		\nonumber\\
		\mathrm{s.t.}\;\; \forall 1 \le i \le N,&\;\;\; y_i(\w^\top \x_i + b) \ge 1 - \xi_i , \nonumber \\
		&\;\;\; \xi_i \ge 0 \nonumber
		\end{align}
		where $N$ is the number of the training examples.
	As we discussed in the class, the slack variables $\{\xi_i\}$ are introduced to allow the training examples to break into the margin so that we can learn a linear classifier even when the data is not linearly separable. 
	\begin{enumerate}
		\item~[3 point] What values $\xi_i$ can take when the training example $\x_i$ breaks into the margin? 

\item[{\bf Answer.}] If $x_i$ breaks into the margin, but correctly classified, then it should be between 0 and 1. That is, when $\xi_i \in (0,1]$. 

If $x_i$ breaks into the margin, but is incorrectly classified, then it should be bigger than 1 and less than 2. That is, when $1<\xi_i <2$. 

		\item~[3 point] What values $\xi_i$ can take when the training example $\x_i$ stays on or outside the margin? 
		
\item[{\bf Answer.}] If $x_i$ is correctly classified, then $\xi_i$ should be zero. 

If $x_i$ is incorrectly classified, but stays on or outside the margin, then $\xi_i \geq 2$. 



		\item~[3 point] Why do we incorporate the term $C\cdot\sum_i \xi_i $ in the objective function? What will happen if we throw out this term? 
		
\item[{\bf Answer.}] We incorporate the sum $\sum_i \xi_i $ to penalize weight vectors that make mistake. In fact, it allows as few examples as possible to violate the margin. And incorporate $C$ in order to trade off between large margin and small hinge-loss. 

The regularization term tries to maximize the margin. So, if we throw out the term $C\cdot\sum_i \xi_i $, then margin can be maximized arbitrarily, consequently, we will allow many examples to violate the margin and so most examples will be classified wrongly. Moreover, 
the minimum of $\min_{\w, b, \{\xi_i\}} \ \frac{1}{2} \w^\top \w$ would be 0 always (note that 0 would be one of the possible answers of the objective function $\frac{1}{2} \w^\top \w$, which is the smallest possible, as $\xi_i$ can go towards infinity and so satisfy in constraints).
	\end{enumerate}
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%% Q2

	\item~[6 points] Write down the dual optimization problem for soft SVMs.  
	Please clearly indicate the constraints, and explain how it is derived. (Note: do NOT directly copy slides content, write down your own understanding.)
	
\item[{\bf Answer.}] The primal SVM is: 
$$\min_{\w, b, \{\xi_i\}} \ \frac{1}{2} \w^\top \w + C \sum_i \xi_i \quad s.t.  \quad \forall i, \,  y_i(\w^\top \x_x + b) \geq 1 - \xi_i, \, \xi_i \geq 0.$$
Its Lagrange form is:
$$\min_{\w, b, \{\xi_i\}} \max_{\alpha_i \geq 0, \, \beta_i \geq 0} \ \frac{1}{2} \w^\top \w + C \sum_i \xi_i - \sum_i \beta_i\xi_i -\sum_i \alpha_i (y_i(\w^\top \x_i + b) - 1 + \xi_i).$$
This is obtained in a standard way. Just we should note that the constraints are $g_i(x) \leq 0$ and here $-y_i(\w^\top \x_x + b)+ 1 - \xi_i \leq 0$ and $-\xi_i \leq 0$, which justifies the negative signs for two last sums. 

The dual SVM comes from changing the min max problem to max min. So, it is:
$$\max_{\alpha_i \geq 0, \, \beta_i \geq 0} \min_{\w, b, \{\xi_i\}} \ \frac{1}{2} \w^\top \w + C \sum_i \xi_i - \sum_i \beta_i\xi_i -\sum_i \alpha_i (y_i(\w^\top \x_i + b) - 1 + \xi_i).$$
In general, the answer to the dual optimization problem, say $d^*$, is less tan or equal to the answer of primal optimization, say $p^*$, i.e. $d^* \leq p^*$. The difference $p^* - d^*$ is called duality gap. However, thanks to Slater's Theorem, for SVM, duality gap is $0$, that is, $d^* = p^*$. This means that solving dual SVM is solving primal SVM. 

To solve the dual SVM, we call the objective function $L$ and first solve the inner min-optimization problem. As usual, we go through partial derivatives. So, we have to solve the system of equations 
$$\frac{\partial L}{\partial \w} =0, \quad \frac{\partial L}{\partial b} =0, \quad \frac{\partial L}{\partial \xi_i} =0.$$ 
Solving these, we get 
$$\w = \sum_i \alpha_i y_i \x_i, \quad \sum_i \alpha_i y_i = 0, \quad \alpha_i + \beta_i = C.$$
Substituting these into dual SVM we get 
$$\max_{\alpha_i \geq 0, \, \beta_i \geq 0} \  - \frac{1}{2} \sum_i \sum_j y_i y_j \alpha_i \alpha_j \x_i^\top \x_j + \sum_i \alpha_i \quad s.t. \quad \sum_i \alpha_i y_i = 0, \, \alpha_i + \beta_i = C, \ \forall i.$$
Now we can use $0 \geq \beta_i = C - \alpha_i$ to remove $\beta_i$ and get the following form of dual SVM:
$$\max_{0 \leq \alpha_i \leq C, \, \forall i\}, \, \sum_i \alpha_i y_i = 0} \  - \frac{1}{2} \sum_i \sum_j y_i y_j \alpha_i \alpha_j \x_i^\top \x_j + \sum_i \alpha_i.$$
Employing the fact that $\max(-f) = - \min(f)$ we can turn the dual SVM into the following optimization problem:
$$\min_{0 \leq \alpha_i \leq C, \, \forall i\}, \, \sum_i \alpha_i y_i = 0} \  \frac{1}{2} \sum_i \sum_j y_i y_j \alpha_i \alpha_j \x_i^\top \x_j - \sum_i \alpha_i.$$
This is now a quadratic optimization problem that we can utilize existing libraries, for instance in python, to solve it. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%% Q3

	\item~[10 points] Continue with the dual form. Suppose after the training procedure, you have obtained the optimal parameters.
	\begin{enumerate}
	
		\item~[4 points] What parameter values can indicate if an example stays outside the margin?
		
\item[{\bf Answer.}]

		\item~[6 points]  if we want to find out which training examples just sit on the margin (neither inside nor outside), what shall we do? Note you are not allowed to examine if the functional margin (\ie $y_i(\w^\top\x_i +b)$) is $1$.
		
\item[{\bf Answer.}]

	\end{enumerate}
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%% Q4	
	
	\item~[6 points] How can we use the kernel trick to enable SVMs to perform nonlinear classification? What is the corresponding optimization problem?
	
\item[{\bf Answer.}]

%%%%%%%%%%%%%%%%%%%%%%%%%%%% Q5
	%calculate the subgradient
	\item~[9 points] Suppose we have the training dataset shown in Table 1. We want to learn a SVM classifier. We initialize all the model parameters with $0$. We set the learning rates for the first three steps to $\{0.01, 0.005, 0.0025\}$.  Please list the sub-gradients of the SVM objective w.r.t the model parameters for the first three steps, when using the stochastic sub-gradient descent algorithm. 
	\begin{table}[h]
		\centering
		\begin{tabular}{ccc|c}
			$x_1$ & $x_2$ & $x_3$ &  $y$\\ 
			\hline\hline
			$0.5$ & $-1$ & $0.3$ & $1$ \\ \hline
			$-1$ & $-2$ & $-2$ & $-1$\\ \hline
			$1.5$ & $0.2$ & $-2.5$ & $1$\\ \hline
		\end{tabular}
	\caption{Dataset}
	\end{table}

\item[{\bf Answer.}]
We have $\w_0 = [0, 0, 0]$, $b = 0$, $\w^0 = [0, 0, 0, 0]$. We set $N=3$, the number of examples, and $C = 1/3$. According to the algorithm we know that $\nabla J^t = [\w_0;0] - C\cdot N y_i\x_i$ if $y_i\w^\top \x_i \leq 1$ and $ [\w_0;0] $ otherwise. Updating rule for $\w$ is $\w \leftarrow \w - \gamma_t \nabla J^t$. Therefore, we have: 

\item[(1)] Since $y_1\w^{0\top} \x_1 = 0 \leq 1$, we have $\nabla J^1 = [-0.5, 1, -0.3, -1 ]$ and $\w^1 = \w^0 - 0.01 \nabla J^1 = [ 0.005, -0.01,  0.003,  0.01 ]$. 

\item[(2)] Since $y_2\w^{0\top} \x_2 = -0.019 \leq 1$, we have $\nabla J^2 = [-0.995, -2.01 , -1.997,  1]$ and $\w^2 = \w^1 - 0.005 \nabla J^2 = [ 0.01 ,  0.   ,  0.013,  0.005]$.

\item[(3)] Since $y_3\w^{0\top} \x_3 = -0.0125 \leq 1$, we have $\nabla J^3 = [-1.49 , -0.2  ,  2.513, -1]$ and $\w^3 =  \w^2 - 0.0025 \nabla J^2 =  [ 0.014,  0.001,  0.007,  0.007]$. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%% Q6

	%kernel Perceptron
	\item~[\textbf{Bonus}][10 points] Let us derive a dual form for Perceptron. Recall, in each step of Perceptron, we add to the current weights $\w$ (including the bias parameter) $y_i\x_i$ for some misclassified example $(\x_i, y_i)$. We initialize $\w$ with $\mathbf{0}$. So, instead of updating $\w$, we can maintain for each training example $i$ a mistake count $c_i$ --- the number of times the data point $(\x_i, y_i)$ has been misclassified. 
	
	\begin{itemize}
		\item~[2 points] Given the mistake counts of all the training examples, $\{c_1, \ldots, c_N\}$, how can we recover $\w$? How can we make predictions with these mistake counts? 
		
\item[{\bf Answer.}] Since the updating rule is $\w_{t+1} = \w_t + r (y_i \x_i)$, where $r$ is the learning rate, with $\w_0 = 0$ we can recover $\w$ as $\w = \w_0 + r \sum_{i=1}^N c_i y_i \x_i = r \sum_{i=1}^N c_i y_i \x_i$.

The prediction of example $\x$ would be ${\rm sgn}((\sum_{i=1}^N c_i y_i \x_i )^{\top} \x) = {\rm sgn}(\sum_{i=1}^N c_i y_i \x_i^{\top} \x)$. Note that $r$ is a positive constant and so there is no role in sign. 

		\item~[3 points] Can you develop an algorithm that uses mistake counts to learn the Perceptron? Please list the pseudo code. 
		
\item[{\bf Answer.}] The algorithm is: 

\begin{algorithm}[H]
\SetAlgoLined
 {\bf Input:} Training set $D = \{(\x_i, y_i)\}_{i=1}^N$, where $\x_i \in \mathbb{R}^n, y_i \in \{-1,1\}$\;
 {\bf Output:} Weight vector $\w$\;
Initialize $c_i = 0$ for $i = 1, \ldots, N$\;
\For{epoch = $1, \ldots ,T$ \vspace{0.1cm}}
	{Shuffle the data\vspace{0.1cm}\;
	{\For {each training example $(x_i, y_i) \in D$ \vspace{0.1cm}}
		{\If {$y_i \sum_{j=1}^N c_j y_j \x_j^{\top} \x_i < 0$ \vspace{0.2cm}}
		{$c_i = c_i +1$}}}}
Return $\sum_{j=1}^N c_j y_j \x_j^{\top}$
\end{algorithm}


		\item~[5 points] Can you apply the kernel trick to develop a nonlinear Perceptron? If so, how do you conduct classification? Can you give the pseudo code fo learning this kernel Perceptron? 
		
\item[{\bf Answer.}]

	\end{itemize}   
	
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\section{Practice [60 points + 10 bonus ]}
\begin{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%% Q1

	\item~[2 Points] Update your machine learning library. Please check in your implementation of Perceptron, voted Perceptron and average Perceptron algorithms. Remember last time you created the folders ``Perceptron". You can commit your code into the corresponding folders now. Please also supplement README.md with concise descriptions about how to use your code to run these algorithms (how to call the command, set the parameters, etc). Please create a new folder ``SVM" in the same level as these folders.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%% Q2

%kernel perceptron, kernel svms
	\item~[28 points] We will first implement SVM in the primal domain with stochastic sub-gradient descent. We will reuse the  dataset for Perceptron implementation, namely, ``bank-note.zip'' in Canvas. The features and labels are listed in the file ``classification/data-desc.txt''. The training data are stored in the file ``classification/train.csv'', consisting of $872$ examples. The test data are stored in ``classification/test.csv'', and comprise of $500$ examples. In both the training and test datasets, feature values and labels are separated by commas. Set the maximum epochs $T$ to 100. Don't forget to shuffle the training examples at the start of each epoch. Use the curve of the objective function (along with the number of updates) to diagnosis the convergence. Try the hyperparameter $C$ from $\{ \frac{100}{873}, \frac{500}{873,} \frac{700}{873}\}$. Don't forget to convert the labels to be in $\{1, -1\}$.  
	\begin{enumerate}
		\item~[12 points] Use the schedule of learning rate: $\gamma_t = \frac{\gamma_0}{1+\frac{\gamma_0}{d}t}	$. Please tune $\gamma_0$ and $d$ to ensure convergence. For each setting of $C$, report your training and test error. 

	
\item[{\bf Answer.}] I have set $\gamma_0 = 0.001$ and $d = 0.0001$. The results are as follows. Figures are for $C=  \frac{100}{873}, \frac{500}{873,} \frac{700}{873}$ respectively. 
		
\includegraphics[scale=0.45]{Train-Test-Error(a)} 

\includegraphics[scale=0.4]{Convergence-a1} 

\includegraphics[scale=0.4]{Convergence-a2} 

\includegraphics[scale=0.4]{Convergence-a3} 
		
		\item~[12 points] Use the schedule $\gamma_t = \frac{\gamma_0}{1+t}$. Report the training and test error for each setting of C. 
		
\item[{\bf Answer.}] Figures are for $C=  \frac{100}{873}, \frac{500}{873,} \frac{700}{873}$ respectively. 
		
\includegraphics[scale=0.45]{Train-Test-Error(b)} 

\includegraphics[scale=0.4]{Convergence-b1} 

\includegraphics[scale=0.4]{Convergence-b2} 

\includegraphics[scale=0.4]{Convergence-b3} 
		
		\item~[6 points] For each $C$, report the differences between the model parameters learned from the two learning rate schedules, as well as the differences between the training/test errors. What can you conclude? 

\item[{\bf Answer.}] The weight vectors as model parameters learned from the two learning rate schedules are presented in tables in parts (a) and (b). If for each $C$ we calculate Euclidean distance between corresponding weight vectors, regarding learning rate, we get the following numbers:
$$\|W_{100/873}^a - W_{100/873}^b \| = 0.243$$
$$\|W_{500/873}^a - W_{500/873}^b \| = 0.566$$
$$\|W_{700/873}^a - W_{700/873}^b \| = 0.665$$
As we see, their differences in magnitude is not considerable. The direction of all weight vectors are the same as well. 

However, looking at train errors, we observe that for $C= 100/873, 700/873$ it is decreased for $\gamma_0 = d = 0.001$, but for $C = 500/873$ it is increased. Concerning test errors, we see that for $C= 500/873$ it is the same for both setting of hyper-parameters but for $C = 100/873, 700/873$ they are declined when we changed $\gamma_0 = 0.001$ and $d = 0.0001$ in part (a) to $\gamma_0 = d = 0.001$ in part (b).

	\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%% Q3

\item~[30 points] Now let us implement SVM in the dual domain. We use the same dataset, ``bank-note.zip''. You can utilize existing constrained optimization libraries. For Python, we recommend to use ``scipy.optimize.minimize'', and you can learn how to use this API from the document at \url{https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.optimize.minimize.html}.
For Matlab, we recommend to use the internal function ``fmincon''; the document and examples are given at \url{https://www.mathworks.com/help/optim/ug/fmincon.html}. For R, we recommend to use the ``nloptr'' package with detailed documentation at \url{https://cran.r-project.org/web/packages/nloptr/nloptr.pdf}. In principle, you can choose any nonlinear optimization algorithm. But we recommend to use L-BFGS for their robustness and excellent performance in practice. 

\begin{enumerate}
	\item ~[10 points] First, run your dual SVM learning algorithm with   $C$ in $\{\frac{100}{873}, \frac{500}{873}, \frac{700}{873}\}$. Recover the feature weights $\w$ and the bias $b$. Compare with the parameters learned with stochastic sub-gradient descent in the primal domain (in Problem 2) and the same settings of $C$, what can you observe? What do you conclude and why?
	
\item[{\bf Answer.}]

	\item~[15 points] Now, use Gaussian kernel in the dual form to implement the nonlinear SVM. Note that you need to modify both the objective function and the prediction. The Gaussian kernel is defined as follows:
	\[
	k(\x_i, \x_j) = \exp(-\frac{\|\x_i - \x_j\|^2}{\gamma}).
	\]
	Test $\gamma$ from $\{0.1, 0.5, 1,  5, 100\}$ and the hyperparameter $C$ from $\{ \frac{100}{873}, \frac{500}{873},  \frac{700}{873}\}$. List the training and test errors for the combinations of all the $\gamma$ and $C$ values. What is the best combination? Compared with linear SVM with the same settings of $C$, what do you observe? What do you conclude and why?  
	
\item[{\bf Answer.}]

	\item~[5 points] Following (b), for each setting of $\gamma$ and $C$, list the number of support vectors. When $C = \frac{500}{873}$, report the number of overlapped support vectors between consecutive values of $\gamma$, \ie how many support vectors are the same for $\gamma= 0.01$ and $\gamma = 0.1$; how many are the same for  $\gamma = 0.1$ and $\gamma = 0.5$, etc. What do you observe and conclude? Why?
	
\item[{\bf Answer.}]

	\item~[\textbf{Bonus}]~[10 points] Implement the kernel Perceptron algorithm you developed in Problem 8 (Section 1). Use Gaussian kernel and test $\gamma$ from $\{ 0.1, 0.5, 1, 5, 100\}$. List the training and test errors accordingly. Compared with the nonlinear SVM, what do you observe? what do you conclude and why?
	
\item[{\bf Answer.}]

\end{enumerate} 

\end{enumerate}



\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
